{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import các thư viện cần thiết\n",
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import copy\n",
    "import numpy as np\n",
    "# Kiểm tra xem có CUDA (GPU) có sẵn không\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Kích thước mong muốn của hình ảnh đầu ra\n",
    "imsize = 512 if torch.cuda.is_available() else 128  # sử dụng kích thước nhỏ nếu không có GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function: tải hình ảnh và chuyển thành tensor\n",
    "def image_loader(image_name):\n",
    "    loader = transforms.Compose([transforms.Resize(imsize), transforms.ToTensor()])  \n",
    "    image = Image.open(image_name)\n",
    "    # Thêm chiều giả cho batch để phù hợp với input của mạng\n",
    "    image = loader(image).unsqueeze(0)\n",
    "    return image.to(device, torch.float)\n",
    "\n",
    "# Helper function: hiển thị tensor dưới dạng hình ảnh PIL\n",
    "def imshow(tensor, title=None):\n",
    "    unloader = transforms.ToPILImage()  # chuyển đổi lại thành hình ảnh PIL\n",
    "    image = tensor.cpu().clone()  # sao chép tensor để không thay đổi nó\n",
    "    image = image.squeeze(0)      # loại bỏ chiều giả của batch\n",
    "    image = unloader(image)\n",
    "    plt.imshow(image)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # tạm dừng một chút để cập nhật đồ thị\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lớp ContentLoss: Tính toán mất mát giữa ảnh nội dung và ảnh mục tiêu\n",
    "class ContentLoss(nn.Module):\n",
    "    def __init__(self, target):\n",
    "        super(ContentLoss, self).__init__()\n",
    "        self.target = target.detach()\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.loss = F.mse_loss(input, self.target)\n",
    "        return input\n",
    "\n",
    "# Hàm gram_matrix: Tính toán ma trận Gram cho ảnh style\n",
    "def gram_matrix(input):\n",
    "    a, b, c, d = input.size()  # a=batch size(=1)\n",
    "    features = input.view(a * b, c * d)  # thay đổi kích thước\n",
    "    G = torch.mm(features, features.t())  # tính toán ma trận Gram\n",
    "    return G.div(a * b * c * d)\n",
    "\n",
    "# Lớp StyleLoss: Tính toán mất mát giữa ảnh style và ảnh mục tiêu\n",
    "class StyleLoss(nn.Module):\n",
    "    def __init__(self, target_feature):\n",
    "        super(StyleLoss, self).__init__()\n",
    "        self.target = gram_matrix(target_feature).detach()\n",
    "\n",
    "    def forward(self, input):\n",
    "        G = gram_matrix(input)\n",
    "        self.loss = F.mse_loss(G, self.target)\n",
    "        return input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lớp Normalization: Chuẩn hóa ảnh đầu vào cho mô hình VGG\n",
    "class Normalization(nn.Module):\n",
    "    def __init__(self, mean, std):\n",
    "        super(Normalization, self).__init__()\n",
    "        self.mean = torch.tensor(mean).view(-1, 1, 1)\n",
    "        self.std = torch.tensor(std).view(-1, 1, 1)\n",
    "\n",
    "    def forward(self, img):\n",
    "        return (img - self.mean) / self.std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tải hình ảnh style và content\n",
    "style_img = image_loader(\"C:\\\\Users\\\\Admin\\\\Downloads\\\\type3.jpg\")\n",
    "content_img = image_loader(\"C:\\\\Users\\\\Admin\\\\Downloads\\\\me.jpg\")\n",
    "\n",
    "# Kiểm tra kích thước của hình ảnh\n",
    "assert style_img.size() == content_img.size(), \"Hình ảnh style và content phải có kích thước giống nhau\"\n",
    "\n",
    "# Hiển thị hình ảnh style và content\n",
    "plt.ion()\n",
    "plt.figure()\n",
    "imshow(style_img, title='Style Image')\n",
    "\n",
    "plt.figure()\n",
    "imshow(content_img, title='Content Image')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tải mô hình VGG19 đã được huấn luyện từ ImageNet\n",
    "cnn = models.vgg19(pretrained=True).features.to(device).eval()\n",
    "\n",
    "# Các giá trị chuẩn hóa cho mô hình VGG19\n",
    "cnn_normalization_mean = torch.tensor([0.485, 0.456, 0.406]).to(device)\n",
    "cnn_normalization_std = torch.tensor([0.229, 0.224, 0.225]).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm tạo mô hình với các lớp mất mát\n",
    "def get_style_model_and_losses(cnn, normalization_mean, normalization_std,\n",
    "                               style_img, content_img,\n",
    "                               content_layers=['conv_4'],\n",
    "                               style_layers=['conv_1', 'conv_2', 'conv_3', 'conv_4', 'conv_5']):\n",
    "    cnn = copy.deepcopy(cnn)\n",
    "\n",
    "    normalization = Normalization(normalization_mean, normalization_std).to(device)\n",
    "\n",
    "    content_losses = []\n",
    "    style_losses = []\n",
    "\n",
    "    model = nn.Sequential(normalization)\n",
    "    i = 0\n",
    "    for layer in cnn.children():\n",
    "        if isinstance(layer, nn.Conv2d):\n",
    "            i += 1\n",
    "            name = 'conv_{}'.format(i)\n",
    "        elif isinstance(layer, nn.ReLU):\n",
    "            name = 'relu_{}'.format(i)\n",
    "            layer = nn.ReLU(inplace=False)\n",
    "        elif isinstance(layer, nn.MaxPool2d):\n",
    "            name = 'pool_{}'.format(i)\n",
    "        elif isinstance(layer, nn.BatchNorm2d):\n",
    "            name = 'bn_{}'.format(i)\n",
    "        else:\n",
    "            raise RuntimeError('Unrecognized layer: {}'.format(layer.__class__.__name__))\n",
    "\n",
    "        model.add_module(name, layer)\n",
    "\n",
    "        if name in content_layers:\n",
    "            target = model(content_img).detach()\n",
    "            content_loss = ContentLoss(target)\n",
    "            model.add_module(\"content_loss_{}\".format(i), content_loss)\n",
    "            content_losses.append(content_loss)\n",
    "\n",
    "        if name in style_layers:\n",
    "            target_feature = model(style_img).detach()\n",
    "            style_loss = StyleLoss(target_feature)\n",
    "            model.add_module(\"style_loss_{}\".format(i), style_loss)\n",
    "            style_losses.append(style_loss)\n",
    "\n",
    "    for i in range(len(model) - 1, -1, -1):\n",
    "        if isinstance(model[i], ContentLoss) or isinstance(model[i], StyleLoss):\n",
    "            break\n",
    "\n",
    "    model = model[:(i + 1)]\n",
    "\n",
    "    return model, style_losses, content_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm tối ưu hóa input image\n",
    "def get_input_optimizer(input_img):\n",
    "    optimizer = optim.LBFGS([input_img.requires_grad_()])\n",
    "    return optimizer\n",
    "\n",
    "# Hàm chạy neural style transfer\n",
    "def run_style_transfer(cnn, normalization_mean, normalization_std,\n",
    "                       content_img, style_img, input_img, num_steps=300,\n",
    "                       style_weight=1000000, content_weight=1):\n",
    "    print('Building the style transfer model..')\n",
    "    model, style_losses, content_losses = get_style_model_and_losses(cnn,\n",
    "        normalization_mean, normalization_std, style_img, content_img)\n",
    "    optimizer = get_input_optimizer(input_img)\n",
    "\n",
    "    print('Optimizing..')\n",
    "    run = [0]\n",
    "    while run[0] <= num_steps:\n",
    "\n",
    "        def closure():\n",
    "            input_img.data.clamp_(0, 1)\n",
    "            optimizer.zero_grad()\n",
    "            model(input_img)\n",
    "            style_score = 0\n",
    "            content_score = 0\n",
    "\n",
    "            for sl in style_losses:\n",
    "                style_score += sl.loss\n",
    "            for cl in content_losses:\n",
    "                content_score += cl.loss\n",
    "\n",
    "            style_score *= style_weight\n",
    "            content_score *= content_weight\n",
    "\n",
    "            loss = style_score + content_score\n",
    "            loss.backward()\n",
    "\n",
    "            run[0] += 1\n",
    "            if run[0] % 50 == 0:\n",
    "                print(\"run {}:\".format(run))\n",
    "                print('Style Loss : {:4f} Content Loss: {:4f}'.format(\n",
    "                    style_score.item(), content_score.item()))\n",
    "                print()\n",
    "\n",
    "            return style_score + content_score\n",
    "\n",
    "        optimizer.step(closure)\n",
    "\n",
    "    input_img.data.clamp_(0, 1)\n",
    "    return input_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thực thi và hiển thị kết quả\n",
    "input_img = content_img.clone()\n",
    "output = run_style_transfer(cnn, cnn_normalization_mean, cnn_normalization_std,\n",
    "                            content_img, style_img, input_img, num_steps=3000)\n",
    "\n",
    "plt.figure()\n",
    "imshow(output, title='Output Image')\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
